{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7808ba1-c75e-4da9-95bf-b958ac988fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully generated 20000 fake names in 'fake_names.csv'\n",
      "You can now load this file along with your 'real names' file.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "import string\n",
    "\n",
    "# --- Configuration ---\n",
    "FILE_NAME = 'fake_names.csv'\n",
    "NUM_ROWS_TO_GENERATE = 20000\n",
    "FAKE_TITLES = ['Mr', 'Ms', 'Mrs', 'Mstr']\n",
    "# --- End Configuration ---\n",
    "\n",
    "def generate_fake_name():\n",
    "    \"\"\"\n",
    "    Generates a single 'fake' name string.\n",
    "    A fake name has a chance to include:\n",
    "    - Irregular capitalization\n",
    "    - Numbers\n",
    "    - Symbols\n",
    "    \"\"\"\n",
    "    \n",
    "    # Start with a base of random lowercase letters\n",
    "    length = random.randint(4, 10)\n",
    "    name_chars = list(''.join(random.choices(string.ascii_lowercase, k=length)))\n",
    "    \n",
    "    # 1. Add numbers (30% chance)\n",
    "    if random.random() < 0.3:\n",
    "        num_to_add = random.randint(1, 2) # Add 1 or 2 numbers\n",
    "        for _ in range(num_to_add):\n",
    "            insert_pos = random.randint(0, length - 1)\n",
    "            name_chars[insert_pos] = random.choice(string.digits)\n",
    "            \n",
    "    # 2. Add symbols (25% chance)\n",
    "    if random.random() < 0.25:\n",
    "        # Only use a limited set of symbols\n",
    "        symbols = '!@#$%_&'\n",
    "        num_to_add = 1\n",
    "        for _ in range(num_to_add):\n",
    "            insert_pos = random.randint(0, length - 1)\n",
    "            name_chars[insert_pos] = random.choice(symbols)\n",
    "\n",
    "    # 3. Add irregular capitalization (40% chance)\n",
    "    if random.random() < 0.4:\n",
    "        num_to_capitalize = random.randint(1, 3)\n",
    "        for _ in range(num_to_capitalize):\n",
    "            insert_pos = random.randint(0, length - 1)\n",
    "            # Make sure we're capitalizing a letter, not a number/symbol\n",
    "            if name_chars[insert_pos] in string.ascii_lowercase:\n",
    "                name_chars[insert_pos] = name_chars[insert_pos].upper()\n",
    "    else:\n",
    "        # Default to normal .title() case if no irregular caps\n",
    "        # (and it doesn't start with a number/symbol)\n",
    "        if name_chars[0] in string.ascii_lowercase:\n",
    "            name_chars[0] = name_chars[0].upper()\n",
    "\n",
    "    return \"\".join(name_chars)\n",
    "\n",
    "def create_fake_name_csv():\n",
    "    \"\"\"\n",
    "    Creates a CSV file with fake passenger data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(FILE_NAME, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            \n",
    "            # Write the header row\n",
    "            writer.writerow(['Title', 'FirstName', 'MiddleName', 'LastName', 'is_real'])\n",
    "            \n",
    "            # Write the data rows\n",
    "            for _ in range(NUM_ROWS_TO_GENERATE):\n",
    "                title = random.choice(FAKE_TITLES)\n",
    "                first_name = generate_fake_name()\n",
    "                \n",
    "                # --- MODIFIED LINE ---\n",
    "                # MiddleName is now always empty\n",
    "                middle_name = ''\n",
    "                # --- END MODIFICATION ---\n",
    "                \n",
    "                last_name = generate_fake_name()\n",
    "                \n",
    "                # The 'is_real' column is always 0\n",
    "                is_real = 0\n",
    "                \n",
    "                writer.writerow([title, first_name, middle_name, last_name, is_real])\n",
    "                \n",
    "        print(f\"Successfully generated {NUM_ROWS_TO_GENERATE} fake names in '{FILE_NAME}'\")\n",
    "        print(\"You can now load this file along with your 'real names' file.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Run the function to create the file\n",
    "if __name__ == \"__main__\":\n",
    "    create_fake_name_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c21f1d54-13b6-4fe1-80e5-3db5279614dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\abishek\\anaconda3\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\abishek\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12dc5b8d-9012-4aeb-8b96-5adc11872b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 1: Loading and Preparing Data\n",
      "======================================================================\n",
      "\n",
      "Real names loaded: 139952 records\n",
      "Fake names loaded: 20000 records\n",
      "\n",
      "Combined dataset: 159952 total records\n",
      "Data shuffled successfully\n",
      "\n",
      "Class Distribution:\n",
      "  Real names (is_real=1): 139952\n",
      "  Fake names (is_real=0): 20000\n",
      "\n",
      "======================================================================\n",
      "STEP 2: Feature Engineering\n",
      "======================================================================\n",
      "\n",
      "Creating name-based features...\n",
      "Name-based features created:\n",
      "  - Length (fn_length, ln_length)\n",
      "  - Has number (fn_has_number, ln_has_number)\n",
      "  - Has symbol (fn_has_symbol, ln_has_symbol)\n",
      "  - Vowel ratio (fn_vowel_ratio, ln_vowel_ratio)\n",
      "  - Irregular caps (fn_has_irregular_caps, ln_has_irregular_caps)\n",
      "\n",
      "Encoding Title column with OneHotEncoder...\n",
      "One-hot encoding complete: 121 title categories\n",
      "\n",
      "Total features created: 131\n",
      "\n",
      "======================================================================\n",
      "STEP 3: Model Training\n",
      "======================================================================\n",
      "\n",
      "Feature matrix shape: (159952, 131)\n",
      "Target variable shape: (159952,)\n",
      "\n",
      "Training set: 127961 samples\n",
      "Test set: 31991 samples\n",
      "\n",
      "Training XGBoost model...\n",
      "Model training complete!\n",
      "\n",
      "======================================================================\n",
      "STEP 4: Model Evaluation\n",
      "======================================================================\n",
      "\n",
      "                            ACCURACY SCORE                            \n",
      "----------------------------------------------------------------------\n",
      "Accuracy: 0.9931 (99.31%)\n",
      "\n",
      "                        CLASSIFICATION REPORT                         \n",
      "----------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Fake (0)       0.98      0.97      0.97      4000\n",
      "    Real (1)       1.00      1.00      1.00     27991\n",
      "\n",
      "    accuracy                           0.99     31991\n",
      "   macro avg       0.99      0.98      0.98     31991\n",
      "weighted avg       0.99      0.99      0.99     31991\n",
      "\n",
      "\n",
      "                           CONFUSION MATRIX                           \n",
      "----------------------------------------------------------------------\n",
      "                      Predicted Fake  Predicted Real\n",
      "         Actual Fake            3879             121\n",
      "         Actual Real              99           27892\n",
      "\n",
      "                            MODEL INSIGHTS                            \n",
      "----------------------------------------------------------------------\n",
      "True Negatives (Correctly identified fake): 3879\n",
      "False Positives (Fake classified as real): 121\n",
      "False Negatives (Real classified as fake): 99\n",
      "True Positives (Correctly identified real): 27892\n",
      "\n",
      "                    TOP 10 MOST IMPORTANT FEATURES                    \n",
      "----------------------------------------------------------------------\n",
      "                ln_vowel_ratio: 0.4414\n",
      "                fn_vowel_ratio: 0.2065\n",
      "         fn_has_irregular_caps: 0.0550\n",
      "                 fn_has_number: 0.0444\n",
      "         ln_has_irregular_caps: 0.0411\n",
      "                     fn_length: 0.0384\n",
      "                 ln_has_symbol: 0.0325\n",
      "                 ln_has_number: 0.0324\n",
      "                 fn_has_symbol: 0.0324\n",
      "                      title_Mr: 0.0156\n",
      "\n",
      "======================================================================\n",
      "Pipeline Complete!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: LOAD AND PREPARE DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 1: Loading and Preparing Data\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load the real names file (Excel format)\n",
    "real_names_df = pd.read_excel('Passenger Data A-S.xlsx', sheet_name='Sheet1')\n",
    "print(f\"\\nReal names loaded: {len(real_names_df)} records\")\n",
    "\n",
    "# Add the target column for real names (is_real = 1)\n",
    "real_names_df['is_real'] = 1\n",
    "\n",
    "# Load the fake names file (already has is_real = 0)\n",
    "fake_names_df = pd.read_csv('fake_names.csv')\n",
    "print(f\"Fake names loaded: {len(fake_names_df)} records\")\n",
    "\n",
    "# Combine both DataFrames\n",
    "combined_df = pd.concat([real_names_df, fake_names_df], ignore_index=True)\n",
    "print(f\"\\nCombined dataset: {len(combined_df)} total records\")\n",
    "\n",
    "# Crucial: Shuffle the rows to mix real and fake samples\n",
    "combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(\"Data shuffled successfully\")\n",
    "\n",
    "# Display the distribution of classes\n",
    "print(f\"\\nClass Distribution:\")\n",
    "print(f\"  Real names (is_real=1): {(combined_df['is_real'] == 1).sum()}\")\n",
    "print(f\"  Fake names (is_real=0): {(combined_df['is_real'] == 0).sum()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 2: Feature Engineering\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create a features DataFrame with the relevant columns\n",
    "features = combined_df[['Title', 'FirstName', 'LastName']].copy()\n",
    "\n",
    "# Handle missing values in ALL columns BEFORE creating features\n",
    "# This is crucial to prevent NaN errors\n",
    "features['Title'] = features['Title'].fillna('Unknown').astype(str)\n",
    "features['FirstName'] = features['FirstName'].fillna('').astype(str)\n",
    "features['LastName'] = features['LastName'].fillna('').astype(str)\n",
    "\n",
    "print(\"\\nCreating name-based features...\")\n",
    "\n",
    "# --- FirstName Features ---\n",
    "features['fn_length'] = features['FirstName'].str.len()\n",
    "features['fn_has_number'] = features['FirstName'].str.contains(r'\\d', regex=True).astype(int)\n",
    "features['fn_has_symbol'] = features['FirstName'].str.contains(r'[!@#$%_&]', regex=True).astype(int)\n",
    "\n",
    "# Vowel ratio for FirstName\n",
    "def calculate_vowel_ratio(name):\n",
    "    if len(name) == 0:\n",
    "        return 0\n",
    "    vowels = sum(1 for char in name.lower() if char in 'aeiou')\n",
    "    return vowels / len(name)\n",
    "\n",
    "features['fn_vowel_ratio'] = features['FirstName'].apply(calculate_vowel_ratio)\n",
    "\n",
    "# Irregular capitalization (capital letter after first character)\n",
    "def has_irregular_caps(name):\n",
    "    if len(name) <= 1:\n",
    "        return 0\n",
    "    return int(any(char.isupper() for char in name[1:]))\n",
    "\n",
    "features['fn_has_irregular_caps'] = features['FirstName'].apply(has_irregular_caps)\n",
    "\n",
    "# --- LastName Features ---\n",
    "features['ln_length'] = features['LastName'].str.len()\n",
    "features['ln_has_number'] = features['LastName'].str.contains(r'\\d', regex=True).astype(int)\n",
    "features['ln_has_symbol'] = features['LastName'].str.contains(r'[!@#$%_&]', regex=True).astype(int)\n",
    "features['ln_vowel_ratio'] = features['LastName'].apply(calculate_vowel_ratio)\n",
    "features['ln_has_irregular_caps'] = features['LastName'].apply(has_irregular_caps)\n",
    "\n",
    "print(\"Name-based features created:\")\n",
    "print(\"  - Length (fn_length, ln_length)\")\n",
    "print(\"  - Has number (fn_has_number, ln_has_number)\")\n",
    "print(\"  - Has symbol (fn_has_symbol, ln_has_symbol)\")\n",
    "print(\"  - Vowel ratio (fn_vowel_ratio, ln_vowel_ratio)\")\n",
    "print(\"  - Irregular caps (fn_has_irregular_caps, ln_has_irregular_caps)\")\n",
    "\n",
    "# --- One-Hot Encode Title Column ---\n",
    "print(\"\\nEncoding Title column with OneHotEncoder...\")\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "title_encoded = encoder.fit_transform(features[['Title']])\n",
    "\n",
    "# Create column names for the encoded features\n",
    "title_columns = [f'title_{cat}' for cat in encoder.categories_[0]]\n",
    "\n",
    "# Convert to DataFrame\n",
    "title_encoded_df = pd.DataFrame(title_encoded, columns=title_columns, index=features.index)\n",
    "\n",
    "# Drop original Title, FirstName, LastName columns and concatenate encoded features\n",
    "features_final = features.drop(['Title', 'FirstName', 'LastName'], axis=1)\n",
    "features_final = pd.concat([features_final, title_encoded_df], axis=1)\n",
    "\n",
    "print(f\"One-hot encoding complete: {len(title_columns)} title categories\")\n",
    "print(f\"\\nTotal features created: {features_final.shape[1]}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: MODEL TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 3: Model Training\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Define target variable (y) and feature matrix (X)\n",
    "y = combined_df['is_real']\n",
    "X = features_final\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
    "print(f\"Target variable shape: {y.shape}\")\n",
    "\n",
    "# Split data into training and test sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Initialize XGBoost Classifier\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "print(\"\\nTraining XGBoost model...\")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print(\"Model training complete!\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: MODEL EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 4: Model Evaluation\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n{'ACCURACY SCORE':^70}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "# Classification Report\n",
    "print(f\"\\n{'CLASSIFICATION REPORT':^70}\")\n",
    "print(\"-\" * 70)\n",
    "print(classification_report(y_test, y_pred, target_names=['Fake (0)', 'Real (1)']))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"\\n{'CONFUSION MATRIX':^70}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'':>20} {'Predicted Fake':>15} {'Predicted Real':>15}\")\n",
    "print(f\"{'Actual Fake':>20} {cm[0][0]:>15} {cm[0][1]:>15}\")\n",
    "print(f\"{'Actual Real':>20} {cm[1][0]:>15} {cm[1][1]:>15}\")\n",
    "\n",
    "# Additional insights\n",
    "print(f\"\\n{'MODEL INSIGHTS':^70}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"True Negatives (Correctly identified fake): {cm[0][0]}\")\n",
    "print(f\"False Positives (Fake classified as real): {cm[0][1]}\")\n",
    "print(f\"False Negatives (Real classified as fake): {cm[1][0]}\")\n",
    "print(f\"True Positives (Correctly identified real): {cm[1][1]}\")\n",
    "\n",
    "# Feature importance (top 10)\n",
    "print(f\"\\n{'TOP 10 MOST IMPORTANT FEATURES':^70}\")\n",
    "print(\"-\" * 70)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "for idx, row in feature_importance.head(10).iterrows():\n",
    "    print(f\"{row['feature']:>30}: {row['importance']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Pipeline Complete!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4904cbac-7a79-4f9a-913b-8fbef78bc00c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c37b4e7-fcf6-42d0-a319-d56a093365f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
